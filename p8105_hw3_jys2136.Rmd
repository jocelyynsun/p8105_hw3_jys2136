---
title: "p8105_hw3_jys2136"
author: "Jocelyn Sun"
date: "10/14/2021"
output: github_document
---

```{r, libraries, message = FALSE}

library(tidyverse)
library(p8105.datasets)
library(httr)
library(jsonlite)

```


# Problem 1

## Instacart Data

#### Most popular aisles and number of ordered items
```{r, instacart_aisle_count, echo = TRUE, message = FALSE}

data("instacart")

# Finding the number of aisles in instacart:
n_aisle = 
  instacart %>%
  count(aisle) %>%
  arrange(desc(n))


# Looking at the first few rows of data to see which aisles(s) are the most items ordered from:
head(n_aisle, 5)

```

#### Data description
The data set _instacart_ has has `r ncol(instacart)` variables and `r nrow(instacart)` observations. 

There are `r nrow(n_aisle)` aisles and as we can see in the output provided above, the aisles where the most items are ordered from are "fresh vegetables" and "fresh fruits", with `r n_aisle[1,2]` number of items being ordered from "fresh vegetables" and `r n_aisle[2,2]` number of items being ordered from "fresh fruits".


#### Visualizing aisles with  > 10,000 items ordered
```{r, aisle_plot, echo = FALSE}

aisle_plot = 
  n_aisle %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle,n)) %>%
  ggplot(
    aes(x = aisle, y = n)) +
    labs(y = "No. of Items Ordered",
         x = "Aisle Name") +
    geom_bar(stat = "identity", fill = "steelblue") +
    theme_bw() + 
    theme(axis.text.x = element_text(family = "Helvetica",
                                     size = 9, 
                                     angle = 60, 
                                     hjust = 1),
          axis.text.y = element_text(family = "Helvetica"))

aisle_plot

ggsave("aisle_plot.pdf", aisle_plot, width = 8, height = 5)
    
```

**need to add figure legend**
The graph above shows the number of items ordered among aisles that have over 10,000 items ordered, respectively. The frequency of ordered items according to aisle category are ordered from least to greatest, left to right. We can see that the most popular aisles are "fresh vegetables" and "fresh fruits". This is consistent with the findings in the section on [Most popular aisles and number of ordered items].


#### Visualizing the most popular items in the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”
```{r, three_popular_items, echo = FALSE}

pop_aisles =
  instacart %>%
  janitor::clean_names() %>%
  filter(aisle == c("baking ingredients", 
                    "dog food care", 
                    "packaged vegetable fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  rename("frequency" = n) %>%
  mutate(product_rank =  min_rank(desc(frequency)),
         product_name = tolower(product_name)) %>%
  filter(product_rank < 4) %>%
  arrange(aisle, product_rank)
  
 knitr::kable(pop_aisles, caption = "**Table 1: Top three purchased items in aisles “baking ingredients” and “dog food care”**") 

```

The table above shows the most popular items in the specified aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. In the _instacart_ dataset, We can see that there is no data on aisle “packaged vegetables fruits”. There is data on aisles "baking ingredients" and "dog food care". The most popular product in "baking ingredients" is light brown sugar. The most popular product in "dog food care" is organix grain free chicken & vegetable dog food. 


Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

#### Visualizing mean hour of orders for Pink Lady Apples and Coffee Ice Cream on each day of the week
```{r, mean_hour, echo = FALSE, message = FALSE}

mean_hour = 
  instacart %>%
  mutate(product_name = tolower(product_name),
           order_dow = recode(order_dow,
                            "0" = "Sunday",
                            "1" = "Monday",
                            "2" = "Tuesday",
                            "3" = "Wednesday",
                            "4" = "Thursday",
                            "5" = "Friday",
                            "6" = "Saturday")) %>%
  filter(product_name %in% c("pink lady apples", "coffee ice cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(hour = mean(order_hour_of_day)) %>%
  pivot_wider(names_from = order_dow,
              values_from = hour)
  
  knitr::kable(mean_hour, 
               digits = 2, 
               caption = "**Table 2: Mean hour of  orders for pink lady apples and coffee ice cream on each day of the week**")

```


# Problem 2

## Data for Behavioral Risk Factors Surveillance System for Selected Metropolitan Area Risk Trends (SMART) (2002-2010)

#### Cleaning the data:
```{r, brfss, warning = FALSE}

data("brfss_smart2010") 

clean_brfss = 
  brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health",
         response %in% c("Excellent", "Very Good", "Good", "Poor")) %>%
  mutate(response = factor(response, levels = c("Excellent", "Very Good", "Good", "Poor"))) %>%
  separate(locationdesc, c("state", "location", "rest")) %>%
  unite(location, c("location", "rest")) %>%
  arrange(response)

```


#### Which states were observed at 7 or more locations in 2002 & 2010
```{r, brfss_2002}

brfss_2002 = 
  clean_brfss %>%
  filter(year == "2002") %>%
  group_by(state) %>%
  distinct(location) %>% #unique() does not work here
  count(state) %>%
  rename("observations" = "n") %>%
  filter(observations > 6)

brfss_2010 = 
  clean_brfss %>%
  filter(year == "2010") %>%
  group_by(state) %>%
  distinct(location) %>% #unique() does not work here
  count(state) %>%
  rename("observations" = "n") %>%
  filter(observations > 6)

```

In 2002, the following states were observed at 7 or more locations: `r brfss_2002 %>% magrittr::extract2("state")`.

In 2010, the following states were observed at 7 or more locations: `r brfss_2010 %>% magrittr::extract2("state")`.



Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Make a “spaghetti” plot of this average value over time within a state (that is, make a plot showing a line for each state across years – the geom_line geometry and group aesthetic will help).
```{r}



```


Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.
```{r}

```


