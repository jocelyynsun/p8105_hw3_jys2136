---
title: "p8105_hw3_jys2136"
author: "Jocelyn Sun"
date: "10/14/2021"
output: github_document
---

```{r, libraries, message = FALSE}

library(tidyverse)
library(p8105.datasets)

```


# Problem 1

## Instacart Data

#### Most popular aisles and number of ordered items
```{r, instacart_aisle_count, echo = FALSE, message = FALSE}

data("instacart")

# Finding the number of aisles in instacart:
n_aisle = 
  instacart %>%
  count(aisle) %>%
  arrange(desc(n))


# Looking at the first few rows of data to see which aisles(s) are the most items ordered from:
n_aisle_lmtd = 
  head(n_aisle, 5)

knitr::kable(n_aisle_lmtd, align = "lc")


```

#### Data description
The dataset **instacart** has has `r ncol(instacart)` variables and `r nrow(instacart)` observations. 

There are `r nrow(n_aisle)` aisles and as we can see in the output provided above, the aisles where the most items are ordered from are _fresh vegetables_ and _fresh fruits_, with `r n_aisle[1,2]` number of items being ordered from _fresh vegetables_ and `r n_aisle[2,2]` number of items being ordered from _fresh fruits_.


#### Visualizing aisles with  > 10,000 items ordered
```{r, aisle_plot, echo = FALSE}

aisle_plot = 
  n_aisle %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle,n)) %>%
  ggplot(
    aes(x = aisle, y = n)) +
    labs(y = "No. of Items Ordered",
         x = "Aisle Name",
         title = "Fig. 1: Aisles with over 10,000 items ordered from Instacart") +
    geom_bar(stat = "identity", fill = "steelblue") +
    theme_bw() + 
    theme(axis.text.x = element_text(family = "Helvetica",
                                     size = 9, 
                                     angle = 60, 
                                     hjust = 1),
          axis.text.y = element_text(family = "Helvetica"),
          plot.title = element_text(family = "Helvetica", face = "bold", size = 12, hjust = 0.5))

aisle_plot

ggsave("aisle_plot.pdf", aisle_plot, width = 8, height = 5)
    
```

The graph above shows the number of items ordered among aisles that have over 10,000 items ordered, respectively. The frequency of ordered items according to aisle category are ordered from least to greatest, left to right. We can see that the most popular aisles are _fresh vegetables_ and _fresh fruits_. This is consistent with the findings in the section on [Most popular aisles and number of ordered items].


#### Visualizing the most popular items in the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”
```{r, three_popular_items, echo = FALSE}

pop_aisles =
  instacart %>%
  janitor::clean_names() %>%
  filter(aisle == c("baking ingredients", 
                    "dog food care", 
                    "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  rename("frequency" = n) %>%
  mutate(product_rank =  min_rank(desc(frequency)),
         product_name = tolower(product_name)) %>%
  filter(product_rank < 4) %>%
  arrange(aisle, product_rank)
  
knitr::kable(pop_aisles, caption = "**Table 1: Top three purchased items in aisles “baking ingredients” and “dog food care”**") 

```

The table above shows the most popular items in the specified aisles **_baking ingredients_**, **_dog food care_**, and **_packaged vegetables fruits_**. In the **instacart** dataset, the most popular product in **_baking ingredients_** is _light brown sugar_. The most popular product in **_dog food care_** is _organix grain free chicken & vegetable dog food_, and the most popular product in **_packaged vegetables fruits_** is _organic baby spinach_.


#### Visualizing mean hour of orders for Pink Lady Apples and Coffee Ice Cream on each day of the week
```{r, mean_hour, echo = FALSE, message = FALSE}

mean_hour = 
  instacart %>%
  mutate(product_name = tolower(product_name),
           order_dow = recode(order_dow,
                            "0" = "Sunday",
                            "1" = "Monday",
                            "2" = "Tuesday",
                            "3" = "Wednesday",
                            "4" = "Thursday",
                            "5" = "Friday",
                            "6" = "Saturday")) %>%
  filter(product_name %in% c("pink lady apples", "coffee ice cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(hour = mean(order_hour_of_day)) %>%
  pivot_wider(names_from = order_dow,
              values_from = hour)
  
  knitr::kable(mean_hour, 
               digits = 2, 
               caption = "**Table 2: Mean hour of  orders for pink lady apples and coffee ice cream on each day of the week**")

```

From the table above, we can generally conclude that _coffee ice cream_ tends to be ordered later in the day compared to orders of _pink lady apples_. The only exception is Friday where we see that the orders for either item come in around the same average time of the day. 

# Problem 2

## Data for Behavioral Risk Factors Surveillance System for Selected Metropolitan Area Risk Trends (SMART) (2002-2010)

#### Cleaning the data:
```{r, brfss, warning = FALSE}

data("brfss_smart2010") 

clean_brfss = 
  brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health",
         response %in% c("Excellent", "Very Good", "Good", "Poor")) %>%
  mutate(response = factor(response, levels = c("Excellent", "Very Good", "Good", "Poor"))) %>%
  separate(locationdesc, c("state", "location", "rest")) %>%
  unite(location, c("location", "rest")) %>%
  arrange(response)

```


#### Which states were observed at 7 or more locations in 2002 & 2010
```{r, brfss_2002}

brfss_2002 = 
  clean_brfss %>%
  filter(year == "2002") %>%
  group_by(state) %>%
  distinct(location) %>% #unique() does not work here
  count(state) %>%
  rename("observations" = "n") %>%
  filter(observations > 6)

brfss_2010 = 
  clean_brfss %>%
  filter(year == "2010") %>%
  group_by(state) %>%
  distinct(location) %>% 
  count(state) %>%
  rename("observations" = "n") %>%
  filter(observations > 6)

knitr::kable(list(brfss_2002, brfss_2010), align = "cr", caption = "Table 3: States with observations at 7 or more locations 2002 (left) & 2010 (right)")

  
```

In 2002, the following states were observed at 7 or more locations: **`r brfss_2002 %>% magrittr::extract2("state")`**.

In 2010, the following states were observed at 7 or more locations: **`r brfss_2010 %>% magrittr::extract2("state")`**.

#### Constructing a spaghetti plot
```{r, spaghetti_plot, echo = FALSE, message = FALSE}

brfss_lmtd = 
  clean_brfss %>%
  filter(response == "Excellent") %>%
  group_by(state, year) %>%
  summarise(mean_data_value = mean(data_value, na.rm = TRUE))

lmtd_plot = 
  ggplot(brfss_lmtd, aes(x = year,
                         y = mean_data_value,
                         color = state)) +
  geom_line(alpha = 0.3, aes(group = state, color = state)) +
  geom_point(alpha = 0.3, aes(group = state, color = state)) +
  labs(
    x = "Year",
    y = "Mean data value",
    title = "Fig. 2: Mean data value in states (2002-2010)") + 
  viridis::scale_color_viridis(name = "state", discrete = T) +
  theme_bw() + 
  theme(axis.text.x = element_text(family = "Helvetica", size = 9),
        axis.text.y = element_text(family = "Helvetica", size = 9),
        plot.title = element_text(family = "Helvetica", face = "bold", size = 12, hjust = 0.5))

lmtd_plot

ggsave("spaghetti_plot.pdf", lmtd_plot, width = 8, height = 5)

```

The plot above shows the mean data values for states that had excellent responses over the years 2002 - 2010.


#### Comparing the mean data values between 2006 and 2010 within the state of NY
```{r, two_panel_plot, echo =  FALSE, message = FALSE}

brfss_dist = 
  clean_brfss %>% 
  filter(year %in% c(2006, 2010),
         state == "NY") %>% 
  group_by(year, response)

# Box plot of data distribution in 2006 & 2010
brfss_dist_plot =
  ggplot(brfss_dist,aes(x = response, y = data_value, color = response)) +
    geom_boxplot() +
    labs(y = "Data Values",
         x = "Responses",
         title = "Fig. 3: Comparison of data values of responses in NY \n (2006 & 2010)") +
    theme_bw() + 
    theme(axis.text.x = element_text(family = "Helvetica",
                                     size = 9, 
                                     angle = 60, 
                                     hjust = 1),
          axis.text.y = element_text(family = "Helvetica"),
          plot.title = element_text(family = "Helvetica", face = "bold", size = 10, hjust = 0.5)) +
    facet_grid(. ~ year)

brfss_dist_plot

ggsave("distr_plot_1.pdf", brfss_dist_plot, width = 8, height = 5)

```
Above is a comparison of the distribution of data values of responses "Excellent" to "Poor" among locations in NY between the years 2006 and 2010.

# Problem 3

## Accelerometer Data

This dataset reflects five weeks of accelerometer data collected on a 63 year-old male with BMI 25, who was admitted to the Advanced Cardiac Care Center of Columbia University Medical Center and diagnosed with congestive heart failure (CHF).

#### Cleaning the data
```{r, clean_accel_data, message = FALSE}

clean_accel = 
  read_csv("data/accel_data.csv") %>% 
  pivot_longer(
    cols = activity.1:activity.1440,
    names_to = "minute",
    values_to = "activity_counts",
    names_prefix = "activity.") %>% 
  mutate(
    minute = as.numeric(minute),
    day = factor(day, levels = c("Monday", 
                                 "Tuesday", 
                                 "Wednesday",
                                 "Thursday", 
                                 "Friday", 
                                 "Saturday", 
                                 "Sunday")),
    weekend_indicator = (day == "Saturday" | day == "Sunday"))

```

The cleaned accelerator data set contains `r nrow(clean_accel)` observations and `r ncol(clean_accel)` variables.   

The variables record the following information for each observation: 
* `week` : the week count, a numeric vector
* `day_id`: the day count, a numeric vector
* `day`: the day of the week, a factor vector with 7 levels associated with each day of the week
* `minute`: the minute of activity, a numeric vector
* `activity_count`: the activity counts for each minute of a 24-hour day starting at midnight, a numeric value
* `weekend_indicator`: a weekend indicator, a logic vector (TRUE if a weekend, FALSE if a weekday)

#### Total activity 
```{r, total_activity, echo = FALSE, message = FALSE}

total_activity = 
  clean_accel %>% 
  group_by(day, week) %>% 
  summarize(total_activity_counts = sum(activity_counts))

total_activity_table =
  total_activity %>%
  pivot_wider(
    names_from = day,
    values_from = total_activity_counts)

knitr::kable(total_activity_table, align = "cccccccc", caption = "**Table 4: Total activity by day of the week**")

total_activity_dist =  
  total_activity %>%
  ggplot(aes(x = day, y = total_activity_counts, color = day)) +
  geom_col() +
  theme_bw() + 
  theme(axis.text.x = element_text(family = "Helvetica",
                                     size = 9, 
                                     angle = 60, 
                                     hjust = 1),
          axis.text.y = element_text(family = "Helvetica"),
          plot.title = element_text(family = "Helvetica", face = "bold", size = 12, hjust = 0.5))
  

total_activity_dist

```

#### Average activity with a day (24 hours)
```{r, plot_24hr_activity, echo = FALSE, message = FALSE}

activity_24hr = 
  clean_accel %>% 
    group_by(day, minute) %>% 
    summarize(avg_value = mean(activity_counts)) %>% 
    ggplot(aes(x = minute, y = avg_value, color = day)) +
    geom_smooth(se = FALSE) +
    scale_x_discrete(limit = c(240, 480, 720, 960, 1200, 1440), 
                     labels = c("4AM", "8AM", "12PM", "4PM", "8PM", "12AM")) +
    labs(
      title = "Fig. 5: Average activity within a 24 hour period  \n for each day of the week",
      x = "Time of day",
      y = "Average activity counts",
      color = "Day of the Week") +
    theme_bw() + 
    theme(axis.text.x = element_text(family = "Helvetica"),
           axis.text.y = element_text(family = "Helvetica"),
           plot.title = element_text(family = "Helvetica", face = "bold", size = 10, hjust = 0.5)) 

activity_24hr

ggsave("activity_24hr.pdf", activity_24hr, width = 8, height = 5)
  
```





