---
title: "p8105_hw3_jys2136"
author: "Jocelyn Sun"
date: "10/14/2021"
output: github_document
---

```{r, libraries, message = FALSE}

library(tidyverse)
library(p8105.datasets)
library(httr)
library(jsonlite)

```


# Problem 1

## Instacart Data

#### Most popular aisles and number of ordered items
```{r, instacart_aisle_count, echo = TRUE, message = FALSE}

data("instacart")

# Finding the number of aisles in instacart:
n_aisle = 
  instacart %>%
  count(aisle) %>%
  arrange(desc(n))


# Looking at the first few rows of data to see which aisles(s) are the most items ordered from:
head(n_aisle, 5)

```

#### Data description
The data set **_instacart_** has has `r ncol(instacart)` variables and `r nrow(instacart)` observations. 

There are `r nrow(n_aisle)` aisles and as we can see in the output provided above, the aisles where the most items are ordered from are _fresh vegetables_ and _fresh fruits_, with `r n_aisle[1,2]` number of items being ordered from _fresh vegetables_ and `r n_aisle[2,2]` number of items being ordered from _fresh fruits_.


#### Visualizing aisles with  > 10,000 items ordered
```{r, aisle_plot, echo = FALSE}

aisle_plot = 
  n_aisle %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle,n)) %>%
  ggplot(
    aes(x = aisle, y = n)) +
    labs(y = "No. of Items Ordered",
         x = "Aisle Name") +
    geom_bar(stat = "identity", fill = "steelblue") +
    theme_bw() + 
    theme(axis.text.x = element_text(family = "Helvetica",
                                     size = 9, 
                                     angle = 60, 
                                     hjust = 1),
          axis.text.y = element_text(family = "Helvetica"))

aisle_plot

ggsave("aisle_plot.pdf", aisle_plot, width = 8, height = 5)
    
```

The graph above shows the number of items ordered among aisles that have over 10,000 items ordered, respectively. The frequency of ordered items according to aisle category are ordered from least to greatest, left to right. We can see that the most popular aisles are _fresh vegetables_ and _fresh fruits_. This is consistent with the findings in the section on [Most popular aisles and number of ordered items].


#### Visualizing the most popular items in the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”
```{r, three_popular_items, echo = FALSE}

pop_aisles =
  instacart %>%
  janitor::clean_names() %>%
  filter(aisle == c("baking ingredients", 
                    "dog food care", 
                    "packaged vegetable fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  rename("frequency" = n) %>%
  mutate(product_rank =  min_rank(desc(frequency)),
         product_name = tolower(product_name)) %>%
  filter(product_rank < 4) %>%
  arrange(aisle, product_rank)
  
 knitr::kable(pop_aisles, caption = "**Table 1: Top three purchased items in aisles “baking ingredients” and “dog food care”**") 

```

The table above shows the most popular items in the specified aisles “baking ingredients”, _dog food care_, and _packaged vegetables fruits_. In the **_instacart_** dataset, We can see that there is no data on aisle _packaged vegetables fruits_. There is data on aisles _baking ingredients_ and _dog food care_. The most popular product in _baking ingredients_ is _light brown sugar_. The most popular product in _dog food care_ is _organix grain free chicken & vegetable dog food_. 


#### Visualizing mean hour of orders for Pink Lady Apples and Coffee Ice Cream on each day of the week
```{r, mean_hour, echo = FALSE, message = FALSE}

mean_hour = 
  instacart %>%
  mutate(product_name = tolower(product_name),
           order_dow = recode(order_dow,
                            "0" = "Sunday",
                            "1" = "Monday",
                            "2" = "Tuesday",
                            "3" = "Wednesday",
                            "4" = "Thursday",
                            "5" = "Friday",
                            "6" = "Saturday")) %>%
  filter(product_name %in% c("pink lady apples", "coffee ice cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(hour = mean(order_hour_of_day)) %>%
  pivot_wider(names_from = order_dow,
              values_from = hour)
  
  knitr::kable(mean_hour, 
               digits = 2, 
               caption = "**Table 2: Mean hour of  orders for pink lady apples and coffee ice cream on each day of the week**")

```


# Problem 2

## Data for Behavioral Risk Factors Surveillance System for Selected Metropolitan Area Risk Trends (SMART) (2002-2010)

#### Cleaning the data:
```{r, brfss, warning = FALSE}

data("brfss_smart2010") 

clean_brfss = 
  brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health",
         response %in% c("Excellent", "Very Good", "Good", "Poor")) %>%
  mutate(response = factor(response, levels = c("Excellent", "Very Good", "Good", "Poor"))) %>%
  separate(locationdesc, c("state", "location", "rest")) %>%
  unite(location, c("location", "rest")) %>%
  arrange(response)

```


#### Which states were observed at 7 or more locations in 2002 & 2010
```{r, brfss_2002}

brfss_2002 = 
  clean_brfss %>%
  filter(year == "2002") %>%
  group_by(state) %>%
  distinct(location) %>% #unique() does not work here
  count(state) %>%
  rename("observations" = "n") %>%
  filter(observations > 6)

brfss_2010 = 
  clean_brfss %>%
  filter(year == "2010") %>%
  group_by(state) %>%
  distinct(location) %>% #unique() does not work here
  count(state) %>%
  rename("observations" = "n") %>%
  filter(observations > 6)

brfss_2002

brfss_2010

```

In 2002, the following states were observed at 7 or more locations: **`r brfss_2002 %>% magrittr::extract2("state")`**.

In 2010, the following states were observed at 7 or more locations: **`r brfss_2010 %>% magrittr::extract2("state")`**.

#### Constructing a spaghetti plot
```{r, spaghetti_plot, echo = FALSE, message = FALSE}

brfss_lmtd = 
  clean_brfss %>%
  filter(response == "Excellent") %>%
  group_by(state, year) %>%
  summarise(mean_data_value = mean(data_value, na.rm = TRUE))

lmtd_plot = 
  ggplot(brfss_lmtd, aes(x = year,
                         y = mean_data_value,
                         color = state)) +
  geom_line(alpha = 0.3, aes(group = state, color = state)) +
  geom_point(alpha = 0.3, aes(group = state, color = state)) +
  labs(
    x = "Year",
    y = "Number of observations in each state",
    title = "Observations in states (2002-2010)") + 
  viridis::scale_color_viridis(name = "state", discrete = T) +
  theme(axis.text.x = element_text(family = "Helvetica", size = 9),
        axis.text.y = element_text(family = "Helvetica", size = 9),
        plot.title = element_text(family = "Helvetica", face = "bold", size = 12, hjust = 0.5))

lmtd_plot

ggsave("spaghetti_plot.pdf", lmtd_plot, width = 8, height = 5)

```

The plot above shows that the majority of states had more than 10 observed locations in during the years 2002 - 2010.

#### Comparing the distribution of mean data values between 2006 and 2010 within the state of NY
```{r, two_panel_plot, echo =  FALSE, message = FALSE}
brfss_dist = 
  clean_brfss %>% 
  filter(year %in% c(2006, 2010),
         state == "NY") %>% 
  group_by(year, response) %>% 
  summarise(mean_data_value = mean(data_value, na.rm = T))

# Bar graph of mean data value distribution 
brfss_dist_plot =
  brfss_dist %>%
  ggplot(aes(x = response, 
               y = mean_data_value, 
               fill = response)) + 
    geom_col(position = "dodge") + 
    labs( x = "Response Level",
          y = "Data Value",
          title = "Distribution of mean data value for responses among locations in NY") +
    theme_bw() + 
    theme(axis.text.x = element_text(family = "Helvetica", size = 9),
        axis.text.y = element_text(family = "Helvetica", size = 9),
        plot.title = element_text(family = "Helvetica", face = "bold", size = 12, hjust = 0.5)) +
    facet_grid(. ~ year)

brfss_dist_plot

ggsave("distr_plot_1.pdf", brfss_dist_plot, width = 8, height = 5)

```


# Problem 3

## Accelerometer Data
```{r, loading_accel_data}

accel_df = read_csv("data/accel_data.csv")

```







